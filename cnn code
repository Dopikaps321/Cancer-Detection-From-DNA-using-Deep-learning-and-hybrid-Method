import os
os.environ----]
os.environ-----S"]="0,2"
import pandas as pd
from tqdm import tqdm
import numpy as np
data=os.listdir('data/')
data
def get_data(data):
    methy_data = pd.read_csv(f'data/{data}', sep='\t', compression='gzip')
    sample_name = methy_data.columns
    CG_id = methy_data.iloc[:, 0].tolist()
    df_data = methy_data.iloc[:, 1:]
    df_data.to_csv(f'{data}_feature.csv', index=False)
    return sample_name

def get_label(sample_name,data):
    label_data = pd.DataFrame(index=["label"], columns=sample_name[1:])
    labels = []
    for i in sample_name[1:]:
        if i[-2:] == '11':
            
            labels.append('0')
        else:
            if data=='BRCA':
                labels.append('1')
            elif data=='COAD':
                labels.append('2')
            elif data=='KIRC':
                labels.append('3')
            elif data=='KIRP':
                labels.append('4')
            elif data=='LIHC':
                labels.append('5')
            elif data=='LUAD':
                labels.append('6')
            elif data=='LUSC':
                labels.append('7')
    label_data.loc['label'] = labels
    df_label = label_data
    df_label.to_csv(f'{data}_label.csv', index=False)
for file in tqdm(data):
    samples_name = get_data(file)
    get_label(samples_name,file)
df1=pd.read_csv('BRCA_feature.csv')
df1.info()
df1.head()
df1=pd.read_csv('BRCA_feature.csv')
df2=pd.read_csv('COAD_feature.csv')
df3=pd.read_csv('KIRC_feature.csv')
df4=pd.read_csv('KIRP_feature.csv')
df5=pd.read_csv('LIHC_feature.csv')
df6=pd.read_csv('LUAD_feature.csv')
df7=pd.read_csv('LUSC_feature.csv')
df_feature=pd.concat([df1,df2,df3,df4,df5,df6,df7],axis=1,ignore_index=True)
df_feature=df_feature.dropna(axis=0)
df1_label=pd.read_csv('BRCA_label.csv')
df2_label=pd.read_csv('COAD_label.csv')
df3_label=pd.read_csv('KIRC_label.csv')
df4_label=pd.read_csv('KIRP_label.csv')
df5_label=pd.read_csv('LIHC_label.csv')
df6_label=pd.read_csv('LUAD_label.csv')
df7_label=pd.read_csv('LUSC_label.csv')
df_label=pd.concat([df1_label,df2_label,df3_label,df4_label,df5_label,df6_label,df7_label],axis=1,ignore_index=True)
df_label.T
X_train=df_feature.T
y_train=df_label.T
from sklearn.decomposition import PCA
pca_feature = PCA(n_components=100)  
X_train_feature=pca_feature.fit_transform(X_train)
!pip install tensorflow
import tensorflow as tf
from tensorflow.keras import backend as K
y_train=y_train.values
y_train_features=y_train.flatten()
from sklearn.model_selection import StratifiedKFold
#from process.CV_Elasticnet import select_feature
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import matthews_corrcoef
from sklearn.metrics import cohen_kappa_score
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping
import seaborn as sns
# Reshape to combine the middle dimensions or choose one dimension
x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2], 1)
x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1] * x_valid.shape[2], 1)
import tensorflow as tf

def MODEL(INPUT_SHAPE):
    model = tf.keras.Sequential([
        tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=INPUT_SHAPE),
        tf.keras.layers.MaxPooling1D(pool_size=2),
        tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'),
        tf.keras.layers.MaxPooling1D(pool_size=2),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dense(8, activation='softmax')
    ])
    
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)
accuracys = []
precisions = []
recalls = []
mccs = []
kappas = []
true_label = []
prediction_label = []
for fold,(train_index, valid_index) in enumerate(skf.split(X_train_feature, y_train_features),1):
    x_train, y_train = X_train_feature[train_index], y_train_features[train_index]
    x_valid, y_valid = X_train_feature[valid_index], y_train_features[valid_index]

    y_train = tf.keras.utils.to_categorical(y_train)
    y_valid = tf.keras.utils.to_categorical(y_valid)
    x_train=np.expand_dims(x_train,axis=2)
    x_valid=np.expand_dims(x_valid,axis=2)
    INPUT_SHAPE = x_train.shape
    model = MODEL(INPUT_SHAPE)
    checkpoint = ModelCheckpoint(f'best_model_fold_{fold}.h5', monitor="val_accuracy", mode="auto",save_best_only=True, verbose=1)
    early_stop = EarlyStopping(monitor='val_accuracy', patience=5, verbose=1,
                               mode='auto', restore_best_weights=True)

    reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=3,
                                  verbose=1, mode='auto')
    callbacks = [checkpoint,early_stop,reduce_lr]
    model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=30, batch_size=32, callbacks=callbacks, verbose=1)

    y_valid = np.argmax(y_valid, axis=1)
    y_pre = model.predict(x_valid)
    y_pre= np.argmax(y_pre, axis=1)
    accuracy = accuracy_score(y_valid, y_pre)
    accuracys.append(accuracy)
    precision = precision_score(y_valid, y_pre, labels=[0, 1, 2, 3, 4, 5, 6, 7], average='macro')
    precisions.append(precision)
    recall = recall_score(y_valid, y_pre, labels=[0, 1, 2, 3, 4, 5, 6, 7], average='macro')
    recalls.append(recall)
    mcc = matthews_corrcoef(y_valid, y_pre)
    mccs.append(mcc)
    kappa = cohen_kappa_score(y_valid, y_pre, labels=None)
    kappas.append(kappa)
    cm = confusion_matrix(y_valid, y_pre)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(8), yticklabels=range(8))
    plt.xlabel("Predicted Labels")
    plt.ylabel("True Labels")
    plt.title(f"Confusion Matrix - Fold {fold}")
    plt.show()

    print(f"Classification Report - Fold {fold}")
    print(classification_report(y_valid, y_pre, digits=1))
    print(cm)
    print("accuracy = ", accuracy)
    print("precision = ", precision)
    print("recall = ", recall)
    print("mcc = ", mcc)
    print("kappa = ", kappa)
print("The average of accuracy = {:.3%} -std: {:.3f} ".format(np.mean(accuracys), np.std(accuracys)))
print("The average of precision = {:.3%} -std: {:.3f} ".format(np.mean(precisions), np.std(precisions)))
print("The average of recall = {:.3%} -std: {:.3f} ".format(np.mean(recalls), np.std(recalls)))
print("The average of mcc = {:.3%} -std: {:.3f} ".format(np.mean(mccs), np.std(mccs)))
print("The average of kappa = {:.3%} -std: {:.3f} ".format(np.mean(kappas), np.std(kappas)))
